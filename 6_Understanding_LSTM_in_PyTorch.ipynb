{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding LSTM in PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj0mduPIBOvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpNYP4qpBsh6",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, The LSTM layers take input as (input_dim, output_dim). Now output_dim in nothing but the number of activation nodes in the layer, also know as hidden_size/hidden_units.\n",
        "The input dim, is the size of input vector, i.e size of a single timestep of a single example.\n",
        "\n",
        "In PyTorch LSTM except their input to be 3 dimensinoal, i.e\n",
        "**(seq_len/number of timesteps, batch_size, input)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYTLfckPBcoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c673d5c9-e53b-4673-9e77-4fd7a5ecb2a3"
      },
      "source": [
        "lstm = nn.LSTM(5, 3)\n",
        "inputs = [torch.randn(1,5) for _ in range(6)]\n",
        "inputs"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-1.1272,  0.4237, -0.1290,  0.9384,  0.1659]]),\n",
              " tensor([[-1.9339,  1.2873,  0.6601, -2.3737, -0.6493]]),\n",
              " tensor([[-0.9119, -0.2122, -0.3635, -0.0915,  0.0601]]),\n",
              " tensor([[-0.6782,  1.1880, -0.8136, -0.1848,  0.1561]]),\n",
              " tensor([[-1.1382,  0.8900,  1.5628, -1.0369, -0.1432]]),\n",
              " tensor([[-0.9382,  1.1817,  1.5930,  1.0027,  0.9704]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOE-EzTZDDf-",
        "colab_type": "text"
      },
      "source": [
        "Hence, the above will be input to the network, which is a list of 4 vector of shape (1,5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Js_bBsoDCdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the hidden state.\n",
        "hidden = (torch.randn(1, 1, 3),\n",
        "          torch.randn(1, 1, 3))\n",
        "\n",
        "for i in inputs:\n",
        "    # Step through the sequence one element at a time.\n",
        "    # after each step, hidden contains the hidden state.\n",
        "    _, hidden = lstm(i.view(1, 1, -1), hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsHKQ9dpDsWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e3f7dba0-b402-408c-ebd2-65daed82128a"
      },
      "source": [
        "hidden"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.0992, -0.1988,  0.4391]]], grad_fn=<StackBackward>),\n",
              " tensor([[[ 0.2067, -0.4157,  0.8444]]], grad_fn=<StackBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWAdK90RD6lv",
        "colab_type": "text"
      },
      "source": [
        "So over here, we are feeding the input and the hidden state from previous time step to the current time-step cell. The final hidden contains output value from the last time step.  Note: they are output value and not activation value.. remember the basics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_DPg5IqFfsG",
        "colab_type": "text"
      },
      "source": [
        "### Weights of LSTM\n",
        "\n",
        "$$it​=σ(Wiixt​+bii​+Whi​h(t−1)​+bhi​)$$\n",
        "$$ft​=σ(Wif​xt​+bif​+Whf​h(t−1)​+bhf​)$$\n",
        "$$gt​=tanh(Wig​xt​+big​+Whg​h(t−1)​+bhg​)$$\n",
        "$$ot​=σ(Wio​xt​+bio​+Who​h(t−1)​+bho​)$$\n",
        "$$ct​=ft​∗c(t−1)​+it​∗gt$$\n",
        "$$​ht​=ot​∗tanh(ct​)$$\n",
        "\n",
        "Now, I see that there are 8 weights, in the above equations, but if shape == shape, then only 4 remain. Hence the state_dict of LSTM should be (output_shape * 4, input_shape), which in this case, shoule be (12, 5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyx2JMBHEYRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "f22b6869-cbb4-465a-cd32-a55793b63581"
      },
      "source": [
        "lstm.state_dict()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih_l0',\n",
              "              tensor([[ 0.0509, -0.5072,  0.2130,  0.0599,  0.4325],\n",
              "                      [ 0.0322, -0.0359, -0.5053, -0.1728, -0.2117],\n",
              "                      [ 0.5532, -0.3448,  0.4821,  0.5737, -0.1600],\n",
              "                      [ 0.4477,  0.4059,  0.1165,  0.0745,  0.0109],\n",
              "                      [ 0.4278, -0.2320,  0.0084, -0.4489, -0.1401],\n",
              "                      [ 0.4040,  0.3669, -0.4151, -0.4016,  0.1966],\n",
              "                      [ 0.0455, -0.5709,  0.3468, -0.0290,  0.1532],\n",
              "                      [ 0.2783, -0.1945,  0.0117, -0.2531,  0.4458],\n",
              "                      [ 0.3351,  0.2846,  0.4378,  0.3740, -0.5650],\n",
              "                      [ 0.2323, -0.0755,  0.0764, -0.0998,  0.0061],\n",
              "                      [ 0.2153, -0.0778,  0.0090, -0.0450, -0.0455],\n",
              "                      [-0.4459, -0.2734,  0.5608,  0.0192, -0.5529]])),\n",
              "             ('weight_hh_l0', tensor([[-0.4535,  0.1470, -0.4320],\n",
              "                      [-0.0315,  0.1942, -0.1442],\n",
              "                      [-0.3738, -0.3033,  0.3125],\n",
              "                      [ 0.1858, -0.1571, -0.4774],\n",
              "                      [ 0.1050, -0.4119,  0.3455],\n",
              "                      [ 0.3802,  0.4007,  0.1082],\n",
              "                      [-0.4082, -0.5307,  0.0401],\n",
              "                      [-0.2741,  0.5419, -0.1058],\n",
              "                      [-0.1057, -0.2997,  0.2266],\n",
              "                      [ 0.4802, -0.2524, -0.5183],\n",
              "                      [ 0.1600,  0.2747, -0.3652],\n",
              "                      [-0.3370, -0.1831,  0.4261]])),\n",
              "             ('bias_ih_l0',\n",
              "              tensor([ 0.1850,  0.4596, -0.3114, -0.4080,  0.0019, -0.1378,  0.3744, -0.4505,\n",
              "                       0.3965, -0.4163,  0.1159,  0.3504])),\n",
              "             ('bias_hh_l0',\n",
              "              tensor([-0.0547,  0.3689, -0.1625,  0.1834, -0.1106,  0.2259,  0.1846,  0.3777,\n",
              "                       0.4570,  0.4799,  0.0185,  0.4253]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j44zdhkPIDht",
        "colab_type": "text"
      },
      "source": [
        "### Output of LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6B-JY5vIDKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "95c63562-82c0-474f-cb4c-2556615c7152"
      },
      "source": [
        "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
        "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  \n",
        "\n",
        "print('Input shape:', inputs.shape)\n",
        "out, hidden = lstm(inputs, hidden)\n",
        "print('out shape',out.shape)\n",
        "print('hidden shape',hidden[0].shape, hidden[1].shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([6, 1, 5])\n",
            "out shape torch.Size([6, 1, 3])\n",
            "hidden shape torch.Size([1, 1, 3]) torch.Size([1, 1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbK5h06SIcou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "665c8979-3801-408b-a3ab-facb7049bbe2"
      },
      "source": [
        "out"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.2465, -0.1238, -0.0830]],\n",
              "\n",
              "        [[-0.0680, -0.1076, -0.1673]],\n",
              "\n",
              "        [[-0.1711, -0.0456, -0.1984]],\n",
              "\n",
              "        [[-0.2222, -0.2052, -0.0098]],\n",
              "\n",
              "        [[-0.1096, -0.1382, -0.1539]],\n",
              "\n",
              "        [[-0.1038, -0.1225, -0.1069]]], grad_fn=<StackBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL6i1o1fIgF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "69cdb1ef-1560-4f49-cee4-4d50708272e4"
      },
      "source": [
        "hidden"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.1038, -0.1225, -0.1069]]], grad_fn=<StackBackward>),\n",
              " tensor([[[-0.1823, -0.1720, -0.2417]]], grad_fn=<StackBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A_NVTREVjH2",
        "colab_type": "text"
      },
      "source": [
        "Hence the out variable stores the values of each of the hidden states from each time step. These hiddens states will be useful when we are working with many to many sequence data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAAJ2ppOWyqH",
        "colab_type": "text"
      },
      "source": [
        "### Time distributed dense layer on top of LSTM\n",
        "\n",
        "For seq2seq models, we often need to feed the output of LSTM layers to Linear layers. Now, the input to the linear layer is 2D, while the output from LSTM layer is 3D. It has an extra time axis. So in order to tackle this, we can use [timedistributed Dense layer in Keras](https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/). but ig, Pytorch doesn't has that layer so instead we will use a for loop and feed output from each time step one by one.\n"
      ]
    }
  ]
}